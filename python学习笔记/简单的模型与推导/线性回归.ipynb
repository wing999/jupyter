{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 线性回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 线性回归公式推导\n",
    "公式为：\n",
    "$$ h_{\\theta}(x) = \\theta_{0}+\\theta_{1}x_{1}+\\theta_{2}x_{2} $$\n",
    "\n",
    "> 1. 以上公式可认为 $x_{0}=1$ ,\n",
    "> 2. $\\theta_{i}$为列向量，$x_{i}$也为列向量，$\\sum_{i=0}^{n}\\theta_{i}x_{i}$ 则可转化为 $\\theta^{T}x$\n",
    "> 3. 通过转化后可得到如下公式\n",
    "> \n",
    "$$h_{\\theta}(x) = \\sum_{i=0}^{n}\\theta_{i}x_{i}= \\theta^{T}x$$\n",
    "\n",
    "---\n",
    "\n",
    "> 因为预测值  $\\hat{y}$ 与实际值$y^{i}$之间肯定存在误差$\\varepsilon^{i}$\n",
    "> \n",
    "$$y^{(i)} = \\hat{y}+\\varepsilon^{(i)}$$\n",
    "$$ \\varepsilon^{(i)}=y^{(i)}-\\hat{y}$$\n",
    "\n",
    "---\n",
    "\n",
    "> 1. 误差$\\varepsilon^{i}$是**独立(每条样本数据之间是无联系的)**并且具有相同的分布，通常认为服从均值$\\mu$为0，方差为$\\theta^{2}$ 的**高斯分布(正太分布)**\n",
    "> 2. 正态分布计算的结果其实为概率密度函数\n",
    "> 3. 通过转化得到以下函数\n",
    "> \n",
    "$$ p(\\varepsilon^{(i)}) = \\frac{1}{\\sqrt{2\\pi\\sigma}}exp(-\\frac{(\\varepsilon^{(i)}-\\mu)^{2}}{2\\sigma^{2}})$$\n",
    "$$=\\frac{1}{\\sqrt{2\\pi\\sigma}}exp(-\\frac{(\\varepsilon^{(i)})^{2}}{2\\sigma^{2}})$$\n",
    "\n",
    "------\n",
    "\n",
    "> 1. $p(y^{(i)}|x^{(i)};\\theta)$ 的含义：什么样的$\\theta$跟$x^{(i)}$组合后，能够越接近真实值$y^{i}$的概率最大。\n",
    "$$ p(y^{(i)}|x^{(i)};\\theta) = \\frac{1}{\\sqrt{2\\pi\\sigma}}exp(-\\frac{(y^{(i)}-\\theta^{T}x^{(i)})^{2}}{2\\sigma^{2}})$$\n",
    "\n",
    "---\n",
    "\n",
    "> 1. 最大似然估计$L(\\theta)$\n",
    "> 2. 因为$\\theta$ 要与每个$x$相乘，所以需要累乘$p(y^{(i)}|x^{(i)};\\theta)$ 使得结果概率$L(\\theta)$最大。\n",
    "> $$ L(\\theta)=\\prod_{i=1}^{m}p(y^{(i)}|x^{(i)};\\theta) $$\n",
    "$$= \\prod_{i=1}^{m}\\frac{1}{\\sqrt{2\\pi\\sigma}}exp(-\\frac{(y^{(i)}-\\theta^{T}x^{(i)})^{2}}{2\\sigma^{2}})$$\n",
    "\n",
    "---\n",
    "\n",
    "> 1. 对数自然函数\n",
    "> 2. 求累乘的最大极值问题比较困难，需要进行转换\n",
    "> 3. 这里运用到函数$logAB = logA+logB$\n",
    "> $$l(\\theta)  = \\log{L(\\theta)} \\tag{1}$$\n",
    "> $$=\\log{\\prod_{i=1}^{m}\\frac{1}{\\sqrt{2\\pi\\sigma}}exp(-\\frac{(y^{(i)}-\\theta^{T}x^{(i)})^{2}}{2\\sigma^{2}})} \\tag{2}$$\n",
    "> $$=\\sum_{x=1}^{m}\\log{\\frac{1}{\\sqrt{2\\pi\\sigma}}exp(-\\frac{(y^{(i)}-\\theta^{T}x^{(i)})^{2}}{2\\sigma^{2}})}\\tag{3}$$\n",
    "> $$=m\\log{\\frac{1}{\\sqrt{2\\pi\\sigma}}}-\\frac{1}{\\sigma^{2}}\\frac{1}{2}\\sum_{i=1}^{m}(y^{(i)}-\\theta^{T}x^{(i)})^{2} \\tag{4}$$\n",
    "> 4. 因为要使得最后的值最大。$m\\log{\\frac{1}{\\sqrt{2\\pi\\sigma}}}$为常数，所以要使得$\\frac{1}{\\sigma^{2}}\\frac{1}{2}\\sum_{i=1}^{m}(y^{(i)}-\\theta^{T}x^{(i)})^{2}$最小即可。\n",
    "> $$J(\\theta)=\\frac{1}{2}\\sum_{i=1}^{m}(h_{\\theta}(x^{(i)})-y^{(i)})^{2}$$\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
